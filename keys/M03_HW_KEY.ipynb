{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "tags": []
   },
   "source": [
    "# Metadata\n",
    "\n",
    "```\n",
    "Course: DS 5001 \n",
    "Module: 03: Homework KEY\n",
    "Topics: Inferring and Interpreting Language Models \n",
    "Author: R.C. Alvarado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Use the the following libraries and source text to answer the questions in this assessment. These resources are all available in the course GitHub repo at https://github.com/ontoligent/DS5001-2022-01. \n",
    "  * `data/gutenberg/pg42324.txt`\n",
    "  * `lib/textimporter.py`\n",
    "  * `lib/langmod.py`\n",
    "\n",
    "  \n",
    "Follow this pattern:\n",
    "* Create a new notebook for your work.\n",
    "* Parse the _Frankenstein_ text to generate TOKENS and VOCAB tables.\n",
    "* Create a list of sentences from the TOKENS table and a list of terms from the VOCAB table. \n",
    "* Pass the two lists to an `langmod.NgramCounter` object to generate ngram type tables and models, going up to the trigram level.\n",
    "* Write the code to answer the following questions:\n",
    "  1. List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc. Hint: use the `df.query()` method.  \n",
    "  2. List the following sentences in ascending order of bigram perpexity according to the language model generated from the text:\n",
    "    ```\n",
    "    The monster is on the ice.\n",
    "    Flowers are happy things.\n",
    "    I have never seen the aurora borealis.\n",
    "    He never knew the love of a family.\n",
    "    ```\n",
    "  3. Using the bigram model represented as a matrix, explore the relationship between bigram pairs using the following lists. Hint: use the `.unstack()` method on the feature `n` and then use `.loc[]` to select the first list from the index, and the second list from the columns.\n",
    "     1. `['he','she']` to select the indices.\n",
    "     2. `['said','heard']` to select the columns.\n",
    "  4. Generate 20 sentences using the `.generate_text()` method from the `langmod.NgramLanguageModel` class.\n",
    "  5. Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the `.mle` feature as $p$ in computing $H = \\sum p(ng) \\log_2(1/p(ng))$. Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length? Hint: Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ is its maximum entropy. \n",
    "\n",
    "\n",
    "Hints:\n",
    "* You may use the libraries or cut-and-paste code from the relevant notebooks.\n",
    "* Use the `M03_LanguageModels.ipynb` to see how the objects from the libraries are used.\n",
    "* The story begins with the Preface.\n",
    "* Even though they are not called \"chapters,\" treat the Preface and Letters as chapters.\n",
    "* Don't worry about OOV words or creating and `<UNK>` term in your vocabulary.\n",
    "* You don't have to use the \"START OF PROJECT GUTENBERG ...\", etc., to clip the text. Find the lines where you think the text actually begins and ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"../labs-repo/data\"\n",
    "local_lib = \"../labs-repo/lib\"\n",
    "src_file_path = f'{data_home}/gutenberg/pg42324.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(local_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textimporter import TextImporter\n",
    "from langmod import NgramCounter, NgramLanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohco_pats = [\n",
    "    ('chap', r\"^(?:PREFACE|CHAPTER|LETTER)\\s\", 'm')\n",
    "]\n",
    "clip_pats = [\n",
    "    r\"^M\\. W\\. S\\.\\s*$\",\n",
    "    r\"^THE END\\.\\s*$\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "franky = TextImporter(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  ../labs-repo/data/gutenberg/pg42324.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id m by milestone ^(?:PREFACE|CHAPTER|LETTER)\\s\n",
      "line_str\n",
      "Parsing OHCO level 1 para_num d by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num d by delimitter [.?!;:]+\n",
      "Parsing OHCO level 3 token_num d by delimitter [\\s',-]+\n"
     ]
    }
   ],
   "source": [
    "franky.import_source().parse_tokens().extract_vocab();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>_To</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Saville</td>\n",
       "      <td>saville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>10</th>\n",
       "      <td>lost</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    token_str  term_str\n",
       "chap_id para_num sent_num token_num                    \n",
       "1       0        0        0               _To        to\n",
       "                          1               Mrs       mrs\n",
       "                 1        1           Saville   saville\n",
       "                          2           England   england\n",
       "                 2        0                 _          \n",
       "...                                       ...       ...\n",
       "28      82       1        10             lost      lost\n",
       "                          11               in        in\n",
       "                          12         darkness  darkness\n",
       "                          13              and       and\n",
       "                          14         distance  distance\n",
       "\n",
       "[75721 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4197</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>18.041696</td>\n",
       "      <td>4.173263</td>\n",
       "      <td>0.231312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2976</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>25.443884</td>\n",
       "      <td>4.669247</td>\n",
       "      <td>0.183512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>26.550140</td>\n",
       "      <td>4.730648</td>\n",
       "      <td>0.178178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2647</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>28.606347</td>\n",
       "      <td>4.838263</td>\n",
       "      <td>0.169133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>36.040457</td>\n",
       "      <td>5.171545</td>\n",
       "      <td>0.143493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treating</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candle</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teacher</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pine</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stealth</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6965 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             n  n_chars         p             s          i         h\n",
       "term_str                                                            \n",
       "the       4197        3  0.055427     18.041696   4.173263  0.231312\n",
       "and       2976        3  0.039302     25.443884   4.669247  0.183512\n",
       "i         2852        1  0.037665     26.550140   4.730648  0.178178\n",
       "of        2647        2  0.034957     28.606347   4.838263  0.169133\n",
       "to        2101        2  0.027747     36.040457   5.171545  0.143493\n",
       "...        ...      ...       ...           ...        ...       ...\n",
       "treating     1        8  0.000013  75721.000000  16.208406  0.000214\n",
       "candle       1        6  0.000013  75721.000000  16.208406  0.000214\n",
       "teacher      1        7  0.000013  75721.000000  16.208406  0.000214\n",
       "pine         1        4  0.000013  75721.000000  16.208406  0.000214\n",
       "stealth      1        7  0.000013  75721.000000  16.208406  0.000214\n",
       "\n",
       "[6965 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chap_id', 'para_num', 'sent_num', 'token_num']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.OHCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = franky.gather_tokens(2).sent_str.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to mrs',\n",
       " 'saville england',\n",
       " '',\n",
       " 'st',\n",
       " 'petersburgh dec',\n",
       " '11th 17',\n",
       " 'you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings',\n",
       " 'i arrived here yesterday',\n",
       " 'and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking',\n",
       " 'i am already far north of london']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = franky.VOCAB.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'i', 'of', 'to', 'my', 'a', 'in', 'was', 'that']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = NgramCounter(sents, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.LM[2].n.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc.\n",
    "\n",
    "Hint, use the `df.query()` method.\n",
    "\n",
    "**<span style=\"color:red;\">ISSUE</span>**: If you use `text_importer.py` you get a set of 6, if you parse it yourself you get 5 of the same but a different 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>mle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>monster</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abhorred</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detestable</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gigantic</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellish</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hideous</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miserable</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>monster</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n       mle\n",
       "w0         w1                   \n",
       "<s>        monster   1  0.000011\n",
       "a          monster   3  0.000033\n",
       "abhorred   monster   1  0.000011\n",
       "detestable monster   1  0.000011\n",
       "gigantic   monster   1  0.000011\n",
       "hellish    monster   1  0.000011\n",
       "hideous    monster   1  0.000011\n",
       "miserable  monster   1  0.000011\n",
       "the        monster  20  0.000220\n",
       "this       monster   1  0.000011"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.LM[1].query(\"w1 == 'monster'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "abhorred\n",
    "detestable    \n",
    "gigantic      \n",
    "hellish       \n",
    "hideous       \n",
    "miserable     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying it by hand (as it were) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_line = open(src_file_path, 'r').read()\n",
    "big_line = big_line.lower().replace(\"\\n\", ' ')\n",
    "big_line = re.sub(r\"[\\W_]+\", \" \", big_line)\n",
    "big_line = re.sub(r\"\\s+\", \" \", big_line)\n",
    "tokens = big_line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the project gutenberg ebook of frankenstein by mary w shelley this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or re use it under the terms of the project gutenberg license included with this ebook or online at www gutenberg org title frankenstein or the modern prometheus author mary w shelley release date march 13 2013 ebook 42324 language english start of this project gutenberg ebook frankenstein produced by greg w'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_line[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data = []\n",
    "for i in range(len(tokens)):\n",
    "    bg_data.append(tokens[i:i+2])\n",
    "BG = pd.DataFrame(bg_data, columns=['w0','w1']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40878</th>\n",
       "      <td>a</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33259</th>\n",
       "      <td>abhorred</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48760</th>\n",
       "      <td>cried</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45661</th>\n",
       "      <td>detestable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72064</th>\n",
       "      <td>gigantic</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70652</th>\n",
       "      <td>hellish</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48800</th>\n",
       "      <td>hideous</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18370</th>\n",
       "      <td>miserable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663</th>\n",
       "      <td>the</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19350</th>\n",
       "      <td>this</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               w0       w1\n",
       "40878           a  monster\n",
       "33259    abhorred  monster\n",
       "48760       cried  monster\n",
       "45661  detestable  monster\n",
       "72064    gigantic  monster\n",
       "70652     hellish  monster\n",
       "48800     hideous  monster\n",
       "18370   miserable  monster\n",
       "19663         the  monster\n",
       "19350        this  monster"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.query(\"w1 == 'monster'\").sort_values('w0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "List the following sentences in ascending order of bigram perpexity according to the language model generated from the text.\n",
    "\n",
    "```\n",
    "The monster is on the ice.\n",
    "Flowers are happy things.\n",
    "I have never seen the aurora borealis.\n",
    "He never knew the love of a family.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NgramLanguageModel(train)\n",
    "model.apply_smoothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = \"\"\"\n",
    "The monster is on the ice.\n",
    "Flowers are happy things.\n",
    "I have never seen the aurora borealis.\n",
    "He never knew the love of a family.\n",
    "\"\"\".split('\\n')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [s.lower() for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = NgramCounter(test_sents, vocab)\n",
    "test.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "      <th>len</th>\n",
       "      <th>ng_1_ll</th>\n",
       "      <th>pp1</th>\n",
       "      <th>ng_2_ll</th>\n",
       "      <th>pp2</th>\n",
       "      <th>ng_3_ll</th>\n",
       "      <th>pp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the monster is on the ice.</td>\n",
       "      <td>9</td>\n",
       "      <td>-46.649460</td>\n",
       "      <td>36.334631</td>\n",
       "      <td>-74.688657</td>\n",
       "      <td>314.897754</td>\n",
       "      <td>-213.042107</td>\n",
       "      <td>1.335934e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flowers are happy things.</td>\n",
       "      <td>7</td>\n",
       "      <td>-44.532783</td>\n",
       "      <td>82.243297</td>\n",
       "      <td>-75.997581</td>\n",
       "      <td>1854.477868</td>\n",
       "      <td>-177.397939</td>\n",
       "      <td>4.254725e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have never seen the aurora borealis.</td>\n",
       "      <td>10</td>\n",
       "      <td>-50.323281</td>\n",
       "      <td>32.725155</td>\n",
       "      <td>-87.041808</td>\n",
       "      <td>417.080128</td>\n",
       "      <td>-230.966554</td>\n",
       "      <td>8.969869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he never knew the love of a family.</td>\n",
       "      <td>11</td>\n",
       "      <td>-65.633527</td>\n",
       "      <td>62.538999</td>\n",
       "      <td>-115.580343</td>\n",
       "      <td>1455.504786</td>\n",
       "      <td>-232.560952</td>\n",
       "      <td>2.313915e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sent_str  len    ng_1_ll        pp1  \\\n",
       "0              the monster is on the ice.    9 -46.649460  36.334631   \n",
       "1               flowers are happy things.    7 -44.532783  82.243297   \n",
       "2  i have never seen the aurora borealis.   10 -50.323281  32.725155   \n",
       "3     he never knew the love of a family.   11 -65.633527  62.538999   \n",
       "\n",
       "      ng_2_ll          pp2     ng_3_ll           pp3  \n",
       "0  -74.688657   314.897754 -213.042107  1.335934e+07  \n",
       "1  -75.997581  1854.477868 -177.397939  4.254725e+07  \n",
       "2  -87.041808   417.080128 -230.966554  8.969869e+06  \n",
       "3 -115.580343  1455.504786 -232.560952  2.313915e+06  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.T.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                the monster is on the ice.\n",
       "2    i have never seen the aurora borealis.\n",
       "3       he never knew the love of a family.\n",
       "1                 flowers are happy things.\n",
       "Name: sent_str, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.T.S.sort_values('pp2').sent_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Using the bigram model represented as a matrix, explore the relationship between bigram pairs as done in the \"Explore\" section of the template notebook, but use the following lists. **What might you speculate about gender and communication given the results you see?**\n",
    "* `['he','she']` to select the indices.\n",
    "* `['said','heard']` to select the columns.\n",
    "\n",
    "Hint: use `.unstack()` method on the feature `n` and then use `.loc[]` to select the first list from the index, and the second list from the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGX = model.LM[1].n.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1   said  heard\n",
      "w0              \n",
      "he   21.0    5.0\n",
      "she   3.0    3.0\n"
     ]
    }
   ],
   "source": [
    "print(BGX.loc[['he','she'],['said','heard']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speculation: Men talk more than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Generate a text using the `generate_text` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. THE TURK ENTERED HIS DAUGHTER TO THINK OF ME WITH A KEEN EYE AND OF SELF CONTROL I WAS ALL FLASHED ACROSS MY MEMORY WHEN I SHOULD EXPRESS WOULD BE UNFAIR TO HER BY WHICH I HAD HITHERTO BEEN TO ME.\n",
      "\n",
      "02. I SEEK THE MOST FAVOURABLE PERIOD FOR TRAVELLING IN RUSSIA.\n",
      "\n",
      "03. KREMPE A GREAT DEAL OF SOUND SENSE AND REAL INFORMATION COMBINED IT IS WHICH HE WAS CALLED SISTER OR A BROTHER CAN NEVER WILLINGLY CONTINUE TO ENDURE THEIR PRESENT HARDSHIPS.\n",
      "\n",
      "04. AND I WAS ANSWERED THROUGH THE WAVES.\n",
      "\n",
      "05. THEY PERFORMED TOWARDS HIM THE GREATEST AFFECTION.\n",
      "\n",
      "06. HE WAS A LOVELY PINK.\n",
      "\n",
      "07. BUT IT IS NOT MY DESTINY.\n",
      "\n",
      "08. AFTER WHICH SHE STOOD TO ME BY HIS MANNER THAT I SHOULD HAVE BEEN MY HABITATION.\n",
      "\n",
      "09. .\n",
      "\n",
      "10. I SOON SHALL SEE YOU AGAIN HARDEN YOURSELF TO MY HEART SINK WITHIN ME.\n",
      "\n",
      "11. I LEARNED THAT THERE WAS ANOTHER STILL PARAMOUNT TO THAT IRREMEDIABLE RUIN.\n",
      "\n",
      "12. I SOON SHALL SEE YOU.\n",
      "\n",
      "13. YOUR THREATS CANNOT MOVE ME TO LEAN AGAINST A TREE FOR SUPPORT.\n",
      "\n",
      "14. NATURE DECAYED AROUND ME.\n",
      "\n",
      "15. .\n",
      "\n",
      "16. A CREATURE DESTROYED BY MISERY TO VICE AND BLOODSHED MY WONDER CEASED AND I SHOULD SURVIVE TO ADD TO THIS DISCOURSE WITH THE GREATEST DISDAIN FOR A MORE INTIMATE UNION MAY NOT PART UNTIL YOU HAVE DESTROYED MY MISERABLE EXISTENCE RESTORE THOSE VICTIMS WHOM YOU MAY EASILY IMAGINE THAT YOU INHABIT MY SON.\n",
      "\n",
      "17. CHEMISTRY IS THAT CLINGING LOVE WE HAVE NO END.\n",
      "\n",
      "18. ON THAT NIGHT AT EVIAN AND CONTINUING OUR VOYAGE.\n",
      "\n",
      "19. IT GAVE ME EXTREME DELIGHT.\n",
      "\n",
      "20. AY AY CONTINUED HE PERCEIVING THAT MY FORMER OCCUPATIONS.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the `.mle` feature as $p$ in computing $H = \\sum p(ng) \\log_2(1/p(ng))$\n",
    "\n",
    "Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ is its maximum entropy. \n",
    "\n",
    "Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = []\n",
    "for i in range(3):\n",
    "    N = V**(i+1)\n",
    "    H = (train.LM[i]['mle'] * np.log2(1/train.LM[i]['mle'])).sum()\n",
    "    Hmax = np.log2(N)\n",
    "    R.append(int(round(1 - H/Hmax, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 48, 61]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Redundancy increases."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_LMs.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235.517px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
